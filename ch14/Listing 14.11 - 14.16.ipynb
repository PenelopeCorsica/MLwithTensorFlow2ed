{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(a):\n",
    "    return a.reshape(a.shape[0], 3, 32, 32).mean(1).reshape(a.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    imgs = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    grayscale_imgs = imgs.mean(1)\n",
    "    cropped_imgs = grayscale_imgs[:, 4:28, 4:28]\n",
    "    img_data = cropped_imgs.reshape(data.shape[0], -1)\n",
    "    img_size = np.shape(img_data)[1]\n",
    "    means = np.mean(img_data, axis=1)\n",
    "    meansT = means.reshape(len(means), 1)\n",
    "    stds = np.std(img_data, axis=1)\n",
    "    stdsT = stds.reshape(len(stds), 1)\n",
    "    adj_stds = np.maximum(stdsT, 1.0 / np.sqrt(img_size))\n",
    "    normalized = (img_data - meansT) / adj_stds\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(directory):\n",
    "    names = unpickle('{}/batches.meta'.format(directory))['label_names']\n",
    "    print('names', names)\n",
    "    data, labels = [], []\n",
    "    for i in range(1, 6):\n",
    "        filename = '{}/data_batch_{}'.format(directory, i)\n",
    "        batch_data = unpickle(filename)\n",
    "        if len(data) > 0:\n",
    "            data = np.vstack((data, batch_data['data']))\n",
    "            labels = np.hstack((labels, batch_data['labels']))\n",
    "        else:\n",
    "            data = batch_data['data']\n",
    "            labels = batch_data['labels']\n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data)\n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "(50000, 3072) (50000,)\n"
     ]
    }
   ],
   "source": [
    "names, data, labels = read_data('../data/cifar-10-batches-py')\n",
    "x = tf.placeholder(tf.float32, [None, 24 * 24]) # 5000,576\n",
    "y = tf.placeholder(tf.float32, [None, len(names)]) # 50000, 10\n",
    "W1 = tf.Variable(tf.random_normal([5, 5, 1, 64])) # first convo layer with 64 filters size 5x5, one band greyscale, image input size 24x24\n",
    "b1 = tf.Variable(tf.random_normal([64])) # biases for first convo layer\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 64, 64])) # second convo layer with 64 filters size 5x5, run on the 64 outputs of first layer, image input size 12x12\n",
    "b2 = tf.Variable(tf.random_normal([64])) # biases for the second convo layer\n",
    "W3 = tf.Variable(tf.random_normal([6*6*64, 1024])) # fully connected layer taking output of convo layer which are 64 image inputs size 6x6 and mapping to 32x32 original image \n",
    "b3 = tf.Variable(tf.random_normal([1024])) # biases for fully connected layer\n",
    "W_out = tf.Variable(tf.random_normal([1024, len(names)])) # output weights for final layer of actual labels, 1024 features  mapped to 10 labels one hot encoded - used for hlf correlations\n",
    "b_out = tf.Variable(tf.random_normal([len(names)])) # biases for output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv_with_b = tf.nn.bias_add(conv, b)\n",
    "    conv_out = tf.nn.relu(conv_with_b)\n",
    "    return conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(conv, k=2):\n",
    "    return tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "     padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.get_shape().as_list()[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 18:09:55.380178 4731680192 deprecation.py:323] From <ipython-input-10-934bb6e9a2fc>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_op = model()\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_op, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattmann/git/buildout.python/python-3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6f6a5191f0415e8fbb6f2ffbe3d311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cbb7230ffc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_onehot_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_onehot_vals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#if i % 1000 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#    print(i, accuracy_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/buildout.python/python-3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    onehot_labels = tf.one_hot(labels, len(names), on_value=1., off_value=0., axis=-1)\n",
    "    onehot_vals = sess.run(onehot_labels)\n",
    "    batch_size = len(data) // 200\n",
    "    print('batch size', batch_size)\n",
    "    for j in tqdm(range(0, 1000)):\n",
    "        #print('EPOCH', j)\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch_data = data[i:i+batch_size, :]\n",
    "            batch_onehot_vals = onehot_vals[i:i+batch_size, :]\n",
    "            _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x:batch_data, y: batch_onehot_vals})\n",
    "            #if i % 1000 == 0:\n",
    "            #    print(i, accuracy_val)\n",
    "        #print('DONE WITH EPOCH')\n",
    "        print(j, accuracy_val)\n",
    "  \n",
    "\n",
    "    saver.save(sess, '../models/cifar10-cnn-tf1n-'+str(epochs)+'epochs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_X(x, W1, b1, W2, b2, W3, b3, W_out, b_out):\n",
    "    x_reshaped = tf.reshape(x, shape=[-1, 24, 24, 1])\n",
    "    conv_out1 = conv_layer(x_reshaped, W1, b1)\n",
    "    maxpool_out1 = maxpool_layer(conv_out1)\n",
    "    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    conv_out2 = conv_layer(norm1, W2, b2)\n",
    "    norm2 = tf.nn.lrn(conv_out2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    maxpool_out2 = maxpool_layer(norm2)\n",
    "    maxpool_reshaped = tf.reshape(maxpool_out2, [-1, W3.shape[0]])\n",
    "    local = tf.add(tf.matmul(maxpool_reshaped, W3), b3)\n",
    "    local_out = tf.nn.relu(local)\n",
    "    out = tf.add(tf.matmul(local_out, W_out), b_out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_data):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"../models/cifar10-cnn-tf1n-\"+str(epochs)+\"epochs.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "        W1_val = W1.eval()\n",
    "        b1_val = b1.eval()\n",
    "        W2_val = W2.eval()\n",
    "        b2_val = b2.eval()\n",
    "        W3_val = W3.eval()\n",
    "        b3_val = b3.eval()\n",
    "        W_out_val = W_out.eval()\n",
    "        b_out_val = b_out.eval()\n",
    "        model_x_out = model_X(img_data, W1_val, b1_val, W2_val, b2_val, W3_val, b3_val, W_out_val, b_out_val)\n",
    "        class_num = np.argmax(model_x_out.eval(), axis=1)[0]\n",
    "        class_name = names[np.argmax(model_x_out.eval(), axis=1)[0]]\n",
    "        return (class_num, class_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num, class_name = predict(data[3])\n",
    "print('Class Num', class_num)\n",
    "print('Class', class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(class_name)\n",
    "img = np.reshape(data[3, :], (24,24))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out on test images\n",
    "def read_test_data(directory):\n",
    "    names = unpickle('{}/batches.meta'.format(directory))['label_names']\n",
    "    print('names', names)\n",
    "    data, labels = [], []\n",
    "    \n",
    "    filename = '{}/test_batch'.format(directory)\n",
    "    batch_data = unpickle(filename)\n",
    "    if len(data) > 0:\n",
    "        data = np.vstack((data, batch_data['data']))\n",
    "        labels = np.hstack((labels, batch_data['labels']))\n",
    "    else:\n",
    "        data = batch_data['data']\n",
    "        labels = batch_data['labels']\n",
    "    print(np.shape(data), np.shape(labels))\n",
    "    data = clean(data)\n",
    "    data = data.astype(np.float32)\n",
    "    return names, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names, test_data, test_labels = read_test_data('../data/cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_num, test_class_name = predict(test_data[4])\n",
    "print('Test Class Num', test_class_num)\n",
    "print('Test Class Name', test_class_name)\n",
    "print('Actual Class Label', test_labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(test_class_name)\n",
    "img = np.reshape(test_data[3, :], (24,24))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(test_data, test_names, test_labels):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"../models/cifar10-cnn-tf1n-\"+str(epochs)+\"epochs.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "        W1_val = W1.eval()\n",
    "        b1_val = b1.eval()\n",
    "        W2_val = W2.eval()\n",
    "        b2_val = b2.eval()\n",
    "        W3_val = W3.eval()\n",
    "        b3_val = b3.eval()\n",
    "        W_out_val = W_out.eval()\n",
    "        b_out_val = b_out.eval()\n",
    "        model_x_out = model_X(test_data, W1_val, b1_val, W2_val, b2_val, W3_val, b3_val, W_out_val, b_out_val)\n",
    "        \n",
    "        onehot_test_labels = tf.one_hot(test_labels, len(test_names), on_value=1., off_value=0., axis=-1)\n",
    "        test_correct_pred = tf.equal(tf.argmax(model_x_out, 1), tf.argmax(onehot_test_labels, 1))\n",
    "        test_accuracy = tf.reduce_mean(tf.cast(test_correct_pred, tf.float32))\n",
    "        \n",
    "        print('Test accuracy %f' % (test_accuracy.eval()))  \n",
    "        predictions = tf.argmax(model_x_out, 1).eval()\n",
    "        return (predictions, tf.cast(test_correct_pred, tf.float32).eval(), onehot_test_labels.eval())\n",
    "\n",
    "    \n",
    "predict_vals, test_correct_preds, onehot_test_lbls = get_test_accuracy(test_data, test_names, test_labels)\n",
    "print(predict_vals)\n",
    "print(predict_vals.shape)\n",
    "print(test_correct_preds)\n",
    "print(test_correct_preds.shape)\n",
    "print(onehot_test_lbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_test = label_binarize(test_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "predictions_test = label_binarize(predict_vals, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "n_classes = outcome_test.shape[1]\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(outcome_test[:, i], predictions_test[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "   \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(outcome_test.ravel(), predictions_test.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for class: '+test_names[2])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(test_names[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "roc_mean = np.mean(np.fromiter(roc_auc.values(), dtype=float))\n",
    "plt.title('ROC curve for CIFAR-10 CNN 2000 iter Tensorflow (area = %{0:0.2f})'.format(roc_mean))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img_url(url):\n",
    "    image = color.rgb2gray(imread(url))\n",
    "    print(image.shape)\n",
    "    plt.figure()\n",
    "    plt.title('URL from Internet')\n",
    "    plt.imshow(image, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    new_size = 24,24\n",
    "    image = resize(image, new_size, anti_aliasing=True)\n",
    "    print(image.shape)\n",
    "    images = np.expand_dims(image, axis=0)\n",
    "    print(images.shape)\n",
    "    im_data = images.astype(np.float32)\n",
    "    print(im_data.shape)\n",
    "    prediction = predict(im_data[0])\n",
    "    print(prediction)\n",
    "    print(\"Cropped to 24x24\")\n",
    "    plt.figure()\n",
    "    plt.title('Pic from Internet (24x24): '+str(prediction[1])) # prediction format is (class num,label)\n",
    "    plt.imshow(images[0], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_urls = [\n",
    "    'http://www.torontozoo.com/adoptapond/guide_images/Green%20Frog.jpg', #frog\n",
    "    'https://cdn.cnn.com/cnnnext/dam/assets/160205192735-01-best-cruise-ships-disney-dream-super-169.jpg', #ship\n",
    "    'https://www.sailboston.com/wp-content/uploads/2016/11/amerigo-vespucci.jpg', #ship\n",
    "    'https://upload.wikimedia.org/wikipedia/commons/d/d9/Motorboat_at_Kankaria_lake.JPG', #ship\n",
    "    'https://media.wired.com/photos/5b9c3d5e7d9d332cf364ad66/master/pass/AV-Trucks-187479297.jpg', #truck\n",
    "    'https://images.schoolspecialty.com/images/1581176_ecommfullsize.jpg', #truck\n",
    "    'https://img.purch.com/w/660/aHR0cDovL3d3dy5saXZlc2NpZW5jZS5jb20vaW1hZ2VzL2kvMDAwLzEwNC84MTkvb3JpZ2luYWwvY3V0ZS1raXR0ZW4uanBn', # cat\n",
    "    'https://thehorse.com/wp-content/uploads/2017/01/iStock-510488648.jpg' #horse\n",
    "]\n",
    "\n",
    "predicted_labels = []\n",
    "for url in predict_urls:\n",
    "    pred = predict_img_url(url)\n",
    "    predicted_labels.append(pred)\n",
    "\n",
    "print(predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
